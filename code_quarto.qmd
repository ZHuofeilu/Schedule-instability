---
title: "Schedule instability (code)"
format: html
editor: visual
---

## 

**Data cleaning (using stata)**

``` stata

// cd ./YOUR TARGET WORKING DIRECTORY


use uk_6_wave_caddi,replace
drop if survey == 1
save uk_5_wave_caddi, replace

use uk_5_wave_caddi
keep if emplnow < 5
keep if emplnow > 0
g work_from_home = emplnow
recode work_from_home 1/2 = 1 3/4 = 2
g class=dclasuk
drop if class>3
drop if econstat==9
g child = nkids
recode child 0 = 0 1/5 = 1
gen weekend = 1
replace weekend = 2 if dday > 5 
replace marstat = . if marstat <0 

keep if typical==1
egen pidp = group( mainid diaryord)
order pidp
sort pidp
save 5_wave_cleaned, replace


use 5_wave_cleaned


//g Work
foreach var of varlist pri1-pri144 {
egen w_`var' = anymatch(`var'),v(117)
}

//Housework
foreach var of varlist pri1-pri144 {
egen h_`var' = anymatch(`var'),v(105,106,107,108,121,122,123,124,126)
}

//Free time-leisure actrivities
foreach var of varlist pri1-pri144 {
egen f_`var' = anymatch(`var'),v(102,111,112,113,114,115,116,125,127,128,129,130,131,132,133,135,136)
}

//Personal care
foreach var of varlist pri1-pri144 {
egen p_`var' = anymatch(`var'),v(101,103,104,109,110)
}

//Sleep
foreach var of varlist pri1-pri144 {
egen s_`var' = anymatch(`var'),v(101)
}

save 3days_cleaned, replace

//Frag 
use 3days_cleaned
keep pidp w_pri1-w_pri144
reshape long  w_pri,i(pidp) j(time)
g b=w_pri
xtset pidp time
gen lag=l.b
g c=b-lag
g f=c
keep pidp time f
reshape wide f,i(pidp)j(time)
egen frag_start=rcount( f1-f144 ), c(@==1)
egen frag_end=rcount( f1-f144 ), c(@==-1)

save frag_covid, replace

clear
use 3days_cleaned
merge 1:m pidp using "frag_covid"
keep if _merge == 3
drop _merge

drop if frag_start==0

egen unpaid_1 = rowtotal(h_pri*)
egen paid_1 = rowtotal(w_pri*)
egen personal_1 = rowtotal(p_pri*)
egen sleep = rowtotal(s_pri*)
foreach var of varlist pidp-sleep {
replace `var' = . if `var' <0 
}

save 3days_cleaned, replace
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Loading required package: pacman

```{r}
if (!require("pacman"))
  { install.packages("pacman")   
  library(pacman) }
```

## load and install packages

```{r libraries}
pacman::p_load(TraMineR, TraMineRextras, cluster, RColorBrewer, devtools, haven,                 tidyverse, reshape2, WeightedCluster, nnet, data.table, Statamarkdown, AER, matrixStats)
```

## Load .dta (Stata) Dataset

```{r}
x3 <- read_dta("3days_cleaned.dta")
```

```{r}
#| eval: FALSE

x3 <- read_dta("3days_cleaned(weekday).dta")
##if exclude weekend diaryies, run this line
```

## Read data UKTUS 3days cleaned

## Keep those who have at least 2 diary days (new subset: d2)

With weekend: At this stage, we drop (2905-2368=537) cases

Without weekend: At this stage, we drop (2018-1325=653) cases

```{r}
x3 <- x3 %>%
  group_by(mainid) %>%
  mutate(ndays = n())
d2 <- x3  %>%
  filter(ndays >= 2)
head(d2$mainid)
```

## Calculate the manhattan distance

```{r}
setDT(d2)

distances_df <- d2[, .(distance = dist(.SD, method = "manhattan")), by = mainid, .SDcols = w_pri1:w_pri144]
print(distances_df)

mean_distances <- distances_df[, .(mean_distance = mean(distance)), by = mainid]

d2 <- d2 %>% 
  left_join(mean_distances, by = "mainid")

summary(d2$mean_distance)
```

**Sleep**

```{r}
setDT(d2)

distances_df_s <- d2[, .(distance_s = dist(.SD, method = "manhattan")), by = mainid, .SDcols = s_pri1:s_pri144]
print(distances_df_s)

mean_distances_s <- distances_df_s[, .(mean_distance_s = mean(distance_s)), by = mainid]

d2 <- d2 %>% 
  left_join(mean_distances_s, by = "mainid")

summary(d2$mean_distance_s)
```

**Average fragmentation**

```{r}
average <- d2 %>%
  filter(frag_start != 0) %>%
  group_by(mainid) %>%
  summarise(av_frag_start = mean(frag_start, na.rm = TRUE))

d2 <- d2 %>%
  left_join(average, by = "mainid")
```

```{r}
variance2 <- d2 %>%
  filter(frag_start != 0) %>%
  group_by(mainid) %>%
  summarise(va_frag_start = var(frag_start, na.rm = TRUE))

d2 <- d2 %>%
  left_join(variance2, by = "mainid")
```

**Average pressure**

```{r}
average_pressure <- d2 %>%
  group_by(mainid) %>%
  summarise(av_pressure = mean(pressure, na.rm = TRUE))

d2 <- d2 %>%
  left_join(average_pressure, by = "mainid")
```

```{r}
variance <- d2 %>%
  group_by(mainid) %>%
  summarise(hours_variance = var(paid_1, na.rm = TRUE))

d2 <- d2 %>%
  left_join(variance, by = "mainid")

```

```{r}
diff_hour <- d2 %>%
  arrange(mainid, diaryord) %>%
  group_by(mainid) %>%
  summarise(mean_work_hours_diff = mean(combn(paid_1, 2, function(x) abs(x[1] - x[2])), na.rm = TRUE))

d2 <- d2 %>%
  left_join(diff_hour, by = "mainid")
```

**Enjoyment**

```{r}
average_work_enj <- d2 %>%
  group_by(mainid) %>%
  summarise(av_w_enj = mean(work_enj, na.rm = TRUE))

d2 <- d2 %>%
  left_join(average_work_enj, by = "mainid")
```

```{r}
average_nonwork_enj <- d2 %>%
  group_by(mainid) %>%
  summarise(av_nw_enj = mean(nonwork_enj, na.rm = TRUE))

d2 <- d2 %>%
  left_join(average_nonwork_enj, by = "mainid")
```

## Slice the sample, keep only one observation for each respondent

**With weekend diaries:** At this stage, we drop (2368-969=1399) cases

**Without weekend diaries:** At this stage, we drop (1325-647=678) cases

```{r}
# d2 <- read_dta("d2.dta")
# Am I right to assume that you exported the above d2 file to stata? It does not appear in the syntax file as it should be : this document must be autonomous

d3 <- d2 %>%
  group_by(mainid) %>%
  slice_sample(n = 1)

print(d3)
```

## Predict schedule instability

```{r}
write_dta(d3, "schedule_analysis(weekend).dta")

```

```{r}
#| eval: FALSE

write_dta(d3, "schedule_analysis(weekday).dta")
##only weekday
```

We do the sequence analysis of the workdays:
- we define a sequence object
- we apply the DHD to it
- then we do an hybrid clustering:
  - a partition using K-medoids with 20 medoids
  - then a hierarchical clustering of the 20 medoids (using the flexible ß link)
- the hclus gives hints on how to reduce the number of clusters
- but ultimately, this will be our decision
- this decision will be informed by the plots of the sequences grouped by medoids
- and by some simple descriptive statistiques (start and end of the workday, duration)

```{r}
#| label: seqanalysis

# we ungroup x3 and rename it dat
dat <- ungroup(x3)

# we keep only ids, days and weights

workseq <- dat[, c("pidp", "daywtq", grep("w_pri", names(x3), value = T))]

# we keep only sequences with at least 10 minutes of work
workseq <- workseq[
rowSums(workseq[, grep("w_pri", names(workseq))]) > 0,
]

slots <- grep("w_pri", names(workseq), value = T)

# a trick for generating the labels 10 minutes by 10 minutes
tslots <- tslots <- format(seq.POSIXt(ISOdate(year = 2019, month = 4, day = 8, hour = 4, min = 0), ISOdate(year = 2019, month = 4, day = 9, hour = 3, min =59 ), by = "10 min"),"%H:%M", tz="GMT")

# we define the object sequence

wseq <- seqdef(
  workseq,
  var = slots,
  cnames = tslots,
  alphabet = c("1", "0"),
  cpal = c("grey", "white"),
  labels = c("Work", "No work"),
  xtstep = 1, 
  id = workseq$pidp,
  weights = workseq$daywtq
)

# Average work day
seqdplot(wseq, border = NA)

# sequence analysis
workdist <- seqdist(wseq, method = "DHD", full.matrix = F)

# K-medoids

workmed <- wcKMedoids(
  workdist,
  k = 20, 
  weights = workseq$daywtq
)

workmed_id <- sort(unique(workmed$clustering))

# saving 

workseq$clus20 <- factor(workmed$clustering, levels = workmed_id, labels = 1:20)

# the above two lines are tricks to plot medoids ten by ten

clust_1_10 <- factor(workmed$clustering, levels = workmed_id[1:10], labels = 1:10)
clust_11_20 <- factor(workmed$clustering, levels = workmed_id[11:20], labels = 11:20)


seqdplot(wseq, 
         group = clust_1_10, 
         border = NA, 
         use.layout=TRUE, cols=3)
pdf(file = "figures/clust_1_10.pdf", width = 11.69, height = 8.27)
seqdplot(wseq, 
         group = clust_1_10, 
         border = NA, 
         use.layout=TRUE, cols=3)
dev.off()

seqdplot(wseq, 
         group = clust_11_20, 
         border = NA, 
         use.layout=TRUE, cols=3)
pdf(file = "figures/clust_11_20.pdf", width = 11.69, height = 8.27)
seqdplot(wseq, 
         group = clust_11_20, 
         border = NA, 
         use.layout=TRUE, cols=3)
dev.off()

# distance between medoids
# we need to define a function to extract it from the distance matrix

dij <- function(i, j, n){
  return(n * (i - 1) - i * (i - 1)/2 + j - i)
}

n <- dim(workseq)[1]
nmed <- 20
# Example position in the vector-distance of the first two medoids

dij(
  workmed_id[1],
  workmed_id[2],
  n
)

rdistmed <- rep(NA, nmed*(nmed - 1)/2)

for (i in 1:(nmed - 1)){
  for (j in (i + 1):nmed){
    rdistmed[dij(i, j, nmed)] <- workdist[dij(workmed_id[i], workmed_id[j], n)]
  }
}

rdistmed <- as.numeric(rdistmed)

# we turn the vector into a "R matrix"
attr(rdistmed,"Size") <- nmed
class(rdistmed) <- "dist"
attr(rdistmed,"Diag") <- FALSE
attr(rdistmed,"Upper") <- FALSE

# now when we print rdistmed, it appears as an lower distance matrix
# but under the hood it's a vector…
rdistmed


clus <- agnes(rdistmed, diss = TRUE, method = "flexible", par.method = 0.65)

plot(clus, which.plots = 2)
pdf(file = "figures/dendrogram.pdf", width = 11.69, height = 8.27)
plot(clus, which.plots = 2)
dev.off()

# descriptive statistics

# duration
workseq$duration <- rowSums(workseq[, grep("w_pri", names(workseq))])

# start of the workday
setDT(workseq)
workseq$start_time <- 0

for (i in 1:144){
  workseq[start_time == 0 & workseq[[paste0("w_pri", i) ]] == 1, "start_time"] <- i
}

# end of the workday

workseq$end_time <- 0

for (i in 144:1){
  workseq[end_time == 0 & workseq[[paste0("w_pri", i)]] == 1, "end_time"] <- i
}

# these times need to be shifted to take into account the fact that 
# diaries were filled in between 4:00 am and 4:00 am the next day

translate4 <- function(x){
  x <- x + 24
  x[x > 143] <- x[x > 143] - 144
  x/6
#  if (x <= 143) {
#    res <- x/6
#  } else {
#    res <- (x - 144)/6
#  }
#  res
}

workseq[, `:=`(duration = duration/6, start_time = translate4(start_time), end_time = translate4(end_time))]

statdes <- workseq[
, 
.(
  N = .N,
  duration = round(weighted.mean(duration, daywtq), digits = 2),
  med_start_time = round(weightedMedian(start_time, daywtq), digits = 2),
  med_end_time = round(weightedMedian(end_time, daywtq), digits = 2)
),
by = clus20
][order(clus20)]
statdes
```
